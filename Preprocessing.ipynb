{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tweets for each company are saved in a separate csv file, we preprocess each of them and return a list of dataframes, each dataframe for one company."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:24: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2020-12-09 05:08:11    [FIST, gt, Bekins, Van, Lines,, Inc, gt, Brock...\n",
       "2020-12-09 03:00:24    [HowmetAerospace, announced, that, its, board,...\n",
       "2020-12-08 18:23:36    [RT, t5monkey, Will, Piers, Morgan, and, Suzi,...\n",
       "2020-12-08 15:49:32    [Now, Hiring, Corporate, Counsel,, Emissions, ...\n",
       "2020-12-08 14:18:47    [News, about, our, community, partner, at, Cum...\n",
       "                                             ...                        \n",
       "2020-11-30 17:47:52    [RT, Hoosiers4Renew, In, Indiana,, large, empl...\n",
       "2020-11-30 14:19:41    [Cummins, to, Open, Hydrogen, Fuel, Cell, Plan...\n",
       "2020-11-30 13:54:54    [Construction, on, the, flagship, of, Bering, ...\n",
       "2020-11-30 04:48:41    [DieselGensets, Market, value, to, cross, 21, ...\n",
       "2020-11-30 04:33:20    [PortableGenerators, Market, value, to, hit, 4...\n",
       "Length: 67, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_file = \"./tweets/Cummins Inc.csv\"\n",
    "\n",
    "emoji_pattern = re.compile(\n",
    "    u\"(\\ud83d[\\ude00-\\ude4f])|\"  # emoticons\n",
    "    u\"(\\ud83c[\\udf00-\\uffff])|\"  # symbols & pictographs (1 of 2)\n",
    "    u\"(\\ud83d[\\u0000-\\uddff])|\"  # symbols & pictographs (2 of 2)\n",
    "    u\"(\\ud83d[\\ude80-\\udeff])|\"  # transport & map symbols\n",
    "    u\"(\\ud83c[\\udde0-\\uddff])\"  # flags (iOS)\n",
    "    \"+\", flags=re.UNICODE)\n",
    "\n",
    "def remove_emoji(text):\n",
    "    return emoji_pattern.sub(r'', text)\n",
    "\n",
    "def preprocess_tweet(file):\n",
    "    \n",
    "    tweets_df = pd.read_csv(file, index_col=0)\n",
    "    # drop duplicate\n",
    "    tweets_df.drop_duplicates(inplace=True)\n",
    "    \n",
    "    # some special marks\n",
    "    special_marks = ['&', '\\n', '@', '$', '#', '‚òÜ', '!', '(', ')'\n",
    "                     ',', '.', ';', ':', 'üí∞', '‚úÖ']\n",
    "    \n",
    "    result_series = pd.Series()\n",
    "    for date_time, text in tweets_df.iloc[:, 0].items():\n",
    "        # tokenize\n",
    "        text = remove_emoji(text)\n",
    "        for sm in special_marks:\n",
    "            text = text.replace(sm, \"\")\n",
    "        tokens = text.split(\" \")\n",
    "        \n",
    "        # Stemming and lemmatisation\n",
    "        \n",
    "        result_series[date_time] = tokens\n",
    "        \n",
    "    return result_series\n",
    "\n",
    "preprocess_tweet(example_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:24: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n"
     ]
    }
   ],
   "source": [
    "# processing examples\n",
    "file_list = os.listdir(\"./tweets\")\n",
    "#ÂàÜÂÖ¨Âè∏ÊîæËøõ‰∏çÂêåÁöÑdataframeÂêßÔºü\n",
    "df_list = [preprocess_tweet(\"./tweets/\"+file) for file in file_list]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Align Technology.csv',\n",
       " 'Ameriprise Financial.csv',\n",
       " 'Aon Plc.csv',\n",
       " 'CenterPoint Energy.csv',\n",
       " 'CMCSA.csv',\n",
       " 'Comcast Corporation.csv',\n",
       " 'Cummins Inc.csv',\n",
       " 'Dollar General Corporation.csv',\n",
       " 'Extra Space Storage.csv',\n",
       " 'J.P. Morgan.csv',\n",
       " 'Jack Henry Associates.csv',\n",
       " 'L3Harris Technologies.csv']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
